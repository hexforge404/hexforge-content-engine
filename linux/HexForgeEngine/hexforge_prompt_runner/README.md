ğŸ“„ README.md â€“ Loop Prompt Generator (HexForge Prompt Runner)
markdown
Copy
Edit
# HexForge Prompt Runner

ğŸ§  **AI-Powered Prompt Optimization Loop** using:
- ğŸ–¼ï¸ Stable Diffusion via **ComfyUI**
- ğŸ§ª Prompt refinement via **LLM (e.g., Mistral or LLaVA)**
- ğŸ¯ CLIP + Aesthetic scoring via local scripts
- ğŸ“Š Multi-seed loop logic with auto-pruning and final variant generation

---

## ğŸ“¦ Project Structure

hexforge-prompt-runner/
â”œâ”€â”€ cli.py # Argument parser (flags like --retry, --sleep)
â”œâ”€â”€ config.py # Central config dictionary
â”œâ”€â”€ helpers.py # Logging, scoring, graphing, retry logic
â”œâ”€â”€ payloads.py # Builds ComfyUI payloads
â”œâ”€â”€ refinement.py # Handles LLaVA or fallback LLM-based prompt refinement
â”œâ”€â”€ main.py # Entry point for the full loop
â”œâ”€â”€ templates/
â”‚ â”œâ”€â”€ prompt_templates.json # (Optional) Format rules
â”‚ â””â”€â”€ prompt_guidelines.txt # (Optional) Guidelines

yaml
Copy
Edit

---

## ğŸš€ How to Run

### â–¶ï¸ Prerequisites

- Python 3.10+
- ComfyUI running on `http://localhost:8188`
- Local scoring script: `score_image_engine.sh` in root
- Ollama / LLaVA running at `http://localhost:11434` (if using multimodal)

### ğŸ”§ Install Python requirements

```bash
pip install -r requirements.txt
â–¶ï¸ Run the Loop Generator
bash
Copy
Edit
python main.py --retry 3 --sleep 30 --min_score 7.5
Available Flags (from cli.py)

Flag	Description
--retry	Retry attempts for ComfyUI posts (default: 3)
--sleep	Delay (seconds) after each image is sent to ComfyUI
--min_score	Minimum score threshold for selecting best prompts
--use_llava	Use LLaVA multimodal image feedback (default: True)

ğŸ§  How It Works
Base prompt is refined in loop using LLaVA or fallback LLM.

Each variant is scored with local score_image_engine.sh.

Best-scoring prompts are retained across seed branches.

A visual prompt graph and final variants are generated.

preview.png and best_prompt_result.png are saved to output.

ğŸ“ Outputs
Saved under config["output_dir"] (e.g., /mnt/hdd-storage/...):

*_00001_.png â€“ images per iteration

preview.png â€“ latest best result

best_prompt_result.png â€“ final best

image_scores.csv â€“ scoring log

*_graph.png â€“ visual prompt evolution graph

*_multi_seed_run.json â€“ full metadata log

ğŸ“Œ Notes
You can customize prompt_base and negative_prompt in config.py.

Guidelines and templates are optional, but help provide prompt consistency.

The script works best with a local Ollama instance for fast LLM feedback.

ğŸ› ï¸ Future Features (Planned)
GUI version using PyQt or TUI

Batch blog/image pairing with the HexForge Content Engine

Support for other scoring models (e.g., BLIP)

Â© 2025 HexForge Labs â€” All Rights Reserved

yaml
Copy
Edit

---

Let me know if you want this saved as an actual file now (`README.md`) or if you'd like a VS Code task/alias to run it easily.






